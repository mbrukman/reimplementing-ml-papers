{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": null
      },
      "outputs": [],
      "source": [
        "# Copyright 2022 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#      http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": null
      },
      "source": [
        "[![View on GitHub][github-badge]][github-keras-v3] [![Open In Colab][colab-badge]][colab-keras-v3] [![Open in Binder][binder-badge]][binder-keras-v3]\n",
        "\n",
        "[github-badge]: https://img.shields.io/badge/View-on%20GitHub-blue?logo=GitHub\n",
        "[colab-badge]: https://colab.research.google.com/assets/colab-badge.svg\n",
        "[binder-badge]: https://static.mybinder.org/badge_logo.svg\n",
        "\n",
        "[github-keras-v3]: https://github.com/mbrukman/reimplementing-ml-papers/blob/main/lenet/LeNet_Keras_v3_Subsamping_fixed_scaling_and_learning_rate_decay.ipynb\n",
        "[colab-keras-v3]: https://colab.research.google.com/github/mbrukman/reimplementing-ml-papers/blob/main/lenet/LeNet_Keras_v3_Subsamping_fixed_scaling_and_learning_rate_decay.ipynb\n",
        "[binder-keras-v3]: https://mybinder.org/v2/gh/mbrukman/reimplementing-ml-papers/main?filepath=lenet/LeNet_Keras_v3_Subsamping_fixed_scaling_and_learning_rate_decay.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": null
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "# Download the custom Subsampling layer, activation function, and LeNet model.\n",
        "for module in subsampling activations lenet ; do\n",
        "  if ! [ -f \"${module}.py\" ]; then\n",
        "    curl -sO \"https://raw.githubusercontent.com/mbrukman/reimplementing-ml-papers/main/lenet/${module}.py\"\n",
        "  fi\n",
        "done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": null
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"LeNet-5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " C1 (Conv2D)                 (None, 28, 28, 6)         156       \n",
            "                                                                 \n",
            " S2 (Subsampling)            (None, 14, 14, 6)         12        \n",
            "                                                                 \n",
            " S2_act (Activation)         (None, 14, 14, 6)         0         \n",
            "                                                                 \n",
            " C3 (Conv2D)                 (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " S4 (Subsampling)            (None, 5, 5, 16)          32        \n",
            "                                                                 \n",
            " S4_act (Activation)         (None, 5, 5, 16)          0         \n",
            "                                                                 \n",
            " C5 (Conv2D)                 (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " Flatten (Flatten)           (None, 120)               0         \n",
            "                                                                 \n",
            " F6 (Dense)                  (None, 84)                10164     \n",
            "                                                                 \n",
            " Output (Dense)              (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 61,750\n",
            "Trainable params: 61,750\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Local imports downloaded above.\n",
        "from subsampling import Subsampling\n",
        "from activations import scaled_tanh\n",
        "from lenet import LeNet\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "# Define the model architecture.\n",
        "model = LeNet(subsampling=Subsampling, activation=scaled_tanh)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": null
      },
      "outputs": [],
      "source": [
        "def scheduler(epoch: int, lr: float) -> float:\n",
        "    if epoch < 2:\n",
        "        eta = 0.0005\n",
        "    elif epoch < 5:\n",
        "        eta = 0.0002\n",
        "    elif epoch < 8:\n",
        "        eta = 0.0001\n",
        "    elif epoch < 12:\n",
        "        eta = 0.00005\n",
        "    else:\n",
        "        eta = 0.00001\n",
        "\n",
        "    mu = 0.02\n",
        "    h_kk = 1\n",
        "    return eta / (mu + h_kk)\n",
        "\n",
        "lr_callback = keras.callbacks.LearningRateScheduler(scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": null
      },
      "outputs": [],
      "source": [
        "# Compile the model with optimizer and loss function.\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0005)\n",
        "loss_fn = keras.losses.CategoricalCrossentropy()\n",
        "model.compile(optimizer=opt, loss=loss_fn, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": null
      },
      "source": [
        "For details on the MNIST dataset including a data exploration, see [MNIST directory in my repo](https://github.com/mbrukman/reimplementing-ml-papers/tree/main/datasets/mnist).\n",
        "\n",
        "Here, we will import a shared library to process the MNIST dataset into the format that we need to use below for model training and testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": null
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "# Download our library for processing MNIST dataset.\n",
        "if ! [ -f \"mnist.py\" ]; then\n",
        "  curl -sO https://raw.githubusercontent.com/mbrukman/reimplementing-ml-papers/main/datasets/mnist/mnist.py\n",
        "fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": null
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "\n",
        "import mnist\n",
        "\n",
        "# This will download the MNIST dataset via the Keras library which outputs data\n",
        "# to stdout, so we silence it above to avoid extraneous output.\n",
        "mnist_data = mnist.MNIST()\n",
        "mnist_input_range = (-0.1, 1.175)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": null
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 16s 4ms/step - loss: 0.3410 - accuracy: 0.8947 - lr: 4.9020e-04\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1021 - accuracy: 0.9693 - lr: 4.9020e-04\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0568 - accuracy: 0.9829 - lr: 1.9608e-04\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0457 - accuracy: 0.9862 - lr: 1.9608e-04\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0387 - accuracy: 0.9887 - lr: 1.9608e-04\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0300 - accuracy: 0.9916 - lr: 9.8039e-05\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0268 - accuracy: 0.9923 - lr: 9.8039e-05\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0243 - accuracy: 0.9931 - lr: 9.8039e-05\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0203 - accuracy: 0.9951 - lr: 4.9020e-05\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0191 - accuracy: 0.9953 - lr: 4.9020e-05\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0181 - accuracy: 0.9956 - lr: 4.9020e-05\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0169 - accuracy: 0.9960 - lr: 4.9020e-05\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0148 - accuracy: 0.9968 - lr: 9.8039e-06\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0145 - accuracy: 0.9969 - lr: 9.8039e-06\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0143 - accuracy: 0.9970 - lr: 9.8039e-06\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0140 - accuracy: 0.9972 - lr: 9.8039e-06\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0138 - accuracy: 0.9973 - lr: 9.8039e-06\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0137 - accuracy: 0.9972 - lr: 9.8039e-06\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0135 - accuracy: 0.9973 - lr: 9.8039e-06\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0133 - accuracy: 0.9973 - lr: 9.8039e-06\n"
          ]
        }
      ],
      "source": [
        "# Train the model.\n",
        "#\n",
        "# In this notebook, we scale the input into the range (-0.1, 1.175) as in the\n",
        "# paper and convert the labels y to a categorical (one-hot) encoding from the\n",
        "# default numeric values.\n",
        "#\n",
        "# For consistency, we use the same transformations for the test dataset below.\n",
        "history = model.fit(mnist_data.x_train_scale_custom(mnist_input_range),\n",
        "                    mnist_data.y_train_categorical(),\n",
        "                    epochs=20,\n",
        "                    callbacks=[lr_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": null
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0380 - accuracy: 0.9879\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.0379730761051178, 0.9879000186920166]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "#\n",
        "# Note that we use the same input range scaling and label encoding as above.\n",
        "model.evaluate(mnist_data.x_test_scale_custom(mnist_input_range),\n",
        "               mnist_data.y_test_categorical())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LeNet [v3]: Subsamping, fixed scaling, and learning rate decay in Keras"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}